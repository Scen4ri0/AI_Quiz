[
  { "id": "e1",  "question": "Почему простая нумерация слов (token IDs) не подходит в качестве входа для модели машинного обучения?" },
  { "id": "e2",  "question": "В чём заключается проблема ложной близости при числовом кодировании слов?" },
  { "id": "e3",  "question": "Что такое One Hot Encoding и какую проблему он решает по сравнению с token IDs?" },
  { "id": "e4",  "question": "Почему One Hot Encoding плохо масштабируется на большие словари?" },
  { "id": "e5",  "question": "Почему One Hot Encoding и Bag of Words не отражают семантическую близость слов?" },
  { "id": "e6",  "question": "Что такое Bag of Words и зачем в нём используются n-граммы?" },
  { "id": "e7",  "question": "Почему методы Bag of Words считаются ограниченными для понимания контекста?" },
  { "id": "e8", "question": "Что означает семантическое понимание текста в контексте NLP?" },
  { "id": "e9", "question": "Что такое embedding и чем он принципиально отличается от One Hot Encoding?" },
  { "id": "e10", "question": "Почему отдельные измерения embedding-вектора нельзя интерпретировать напрямую?" },
  { "id": "e11", "question": "В чём концептуальная разница между моделями CBOW и Skip-Gram?" },
  { "id": "e12", "question": "Почему традиционный SQL-поиск плохо подходит для поиска по смыслу?" },
  { "id": "e13", "question": "В чём ключевая идея хранения данных в векторной базе данных?" },
  { "id": "e14", "question": "Почему векторные базы данных переносят основную сложность с пользователя на систему?" },
  { "id": "e15", "question": "Как embeddings используются для семантического поиска документов?" },
  { "id": "e16", "question": "Почему запрос пользователя также преобразуется в embedding при поиске?" },
  { "id": "e17", "question": "Почему размерность embedding-вектора влияет на качество и стоимость поиска?" },
  { "id": "e18", "question": "Что означает порог сходства в векторной базе данных и зачем он нужен?" },
  { "id": "e19", "question": "Почему слишком низкий порог сходства может приводить к нерелевантным результатам?" },
  { "id": "e20", "question": "Почему данные в векторных БД часто разбиваются на фрагменты (chunks)?" },
  { "id": "e21", "question": "Зачем используется перекрытие фрагментов при разбиении документов?" },
  { "id": "e22", "question": "Почему потеря части контекста критична для семантического поиска?" }
]

